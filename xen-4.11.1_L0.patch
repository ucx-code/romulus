diff -ruN /root/xen/xen-original/tools/libxc/include/xenctrl.h /root/xen/xen-modded/tools/libxc/include/xenctrl.h
--- /root/xen/xen-original/tools/libxc/include/xenctrl.h	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/tools/libxc/include/xenctrl.h	2020-06-06 20:20:32.324834606 +0100
@@ -2622,6 +2622,10 @@
 int xc_domain_cacheflush(xc_interface *xch, uint32_t domid,
                          xen_pfn_t start_pfn, xen_pfn_t nr_pfns);
 
+typedef vmcs_save_state_t libxl_vmcs_save_state_t;
+int xc_save_nvmcs(xc_interface *xch, vmcs_save_state_t * state, int step, unsigned long domid);
+int xc_inject_fault(xc_interface *xch, unsigned long domid, unsigned long bit, unsigned long reg, unsigned long range_start, unsigned long range_end);
+
 /* Compat shims */
 #include "xenctrl_compat.h"
 
diff -ruN /root/xen/xen-original/tools/libxc/Makefile /root/xen/xen-modded/tools/libxc/Makefile
--- /root/xen/xen-original/tools/libxc/Makefile	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/tools/libxc/Makefile	2020-06-06 20:20:32.324834606 +0100
@@ -16,6 +16,8 @@
 CTRL_SRCS-$(CONFIG_ARM) += xc_core_arm.c
 CTRL_SRCS-y       += xc_cpupool.c
 CTRL_SRCS-y       += xc_domain.c
+CTRL_SRCS-y       += xc_migration.c
+CTRL_SRCS-y       += xc_faultinjection.c
 CTRL_SRCS-y       += xc_evtchn.c
 CTRL_SRCS-y       += xc_gnttab.c
 CTRL_SRCS-y       += xc_misc.c
diff -ruN /root/xen/xen-original/tools/libxc/xc_faultinjection.c /root/xen/xen-modded/tools/libxc/xc_faultinjection.c
--- /root/xen/xen-original/tools/libxc/xc_faultinjection.c	1970-01-01 01:00:00.000000000 +0100
+++ /root/xen/xen-modded/tools/libxc/xc_faultinjection.c	2020-06-06 20:20:32.324834606 +0100
@@ -0,0 +1,12 @@
+#include "xc_private.h"
+#include "xc_core.h"
+#include "xg_private.h"
+#include "xg_save_restore.h"
+#include <xen/memory.h>
+#include <xen/hvm/hvm_op.h>
+
+int xc_inject_fault(xc_interface *xch, unsigned long domid, unsigned long bit, unsigned long reg, unsigned long range_start, unsigned long range_end)
+{
+	return xencall5(xch->xcall, __HYPERVISOR_fault_injection, domid, bit, reg, range_start, range_end);
+}
+
diff -ruN /root/xen/xen-original/tools/libxc/xc_migration.c /root/xen/xen-modded/tools/libxc/xc_migration.c
--- /root/xen/xen-original/tools/libxc/xc_migration.c	1970-01-01 01:00:00.000000000 +0100
+++ /root/xen/xen-modded/tools/libxc/xc_migration.c	2020-06-06 20:20:32.324834606 +0100
@@ -0,0 +1,24 @@
+#include "xc_private.h"
+#include "xc_core.h"
+#include "xg_private.h"
+#include "xg_save_restore.h"
+#include <xen/memory.h>
+#include <xen/hvm/hvm_op.h>
+
+int xc_save_nvmcs(xc_interface *xch, vmcs_save_state_t * state, int step, unsigned long domid)
+{
+   int ret = -1;
+   DECLARE_HYPERCALL_BUFFER(vmcs_save_state_t, local);
+   local = xc_hypercall_buffer_alloc(xch, local, sizeof(*local));
+   if (state == NULL) {
+      printf("Buffer alloc failed\n");
+      return -1;
+   }
+   ret = xencall3(xch->xcall, __HYPERVISOR_save_nvmcs, HYPERCALL_BUFFER_AS_ARG(local), step, domid);
+
+   if (step == 2)
+      memcpy(state, local, sizeof(*local));
+   xc_hypercall_buffer_free(xch, local);
+   return ret;
+}
+
diff -ruN /root/xen/xen-original/tools/libxl/libxl_faultinjection.c /root/xen/xen-modded/tools/libxl/libxl_faultinjection.c
--- /root/xen/xen-original/tools/libxl/libxl_faultinjection.c	1970-01-01 01:00:00.000000000 +0100
+++ /root/xen/xen-modded/tools/libxl/libxl_faultinjection.c	2020-06-06 20:20:32.325834590 +0100
@@ -0,0 +1,8 @@
+#include "libxl_osdeps.h"
+
+#include "libxl_internal.h"
+
+int libxl_inject_fault(libxl_ctx *ctx, unsigned long domid, unsigned long bit, unsigned long reg, unsigned long range_start, unsigned long range_end)
+{
+    return xc_inject_fault(ctx->xch, domid, bit, reg, range_start, range_end);
+}
diff -ruN /root/xen/xen-original/tools/libxl/libxl.h /root/xen/xen-modded/tools/libxl/libxl.h
--- /root/xen/xen-original/tools/libxl/libxl.h	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/tools/libxl/libxl.h	2020-06-06 20:20:32.325834590 +0100
@@ -954,6 +954,9 @@
  */
 #define LIBXL_HAVE_COLO_USERSPACE_PROXY 1
 
+int libxl_save_nvmcs_state(libxl_ctx * ctx, void * state, int step, unsigned int domid);
+int libxl_inject_fault(libxl_ctx *ctx, unsigned long domid, unsigned long bit, unsigned long reg, unsigned long range_start, unsigned long range_end);
+
 typedef uint8_t libxl_mac[6];
 #define LIBXL_MAC_FMT "%02hhx:%02hhx:%02hhx:%02hhx:%02hhx:%02hhx"
 #define LIBXL_MAC_FMTLEN ((2*6)+5) /* 6 hex bytes plus 5 colons */
diff -ruN /root/xen/xen-original/tools/libxl/libxl_migration.c /root/xen/xen-modded/tools/libxl/libxl_migration.c
--- /root/xen/xen-original/tools/libxl/libxl_migration.c	1970-01-01 01:00:00.000000000 +0100
+++ /root/xen/xen-modded/tools/libxl/libxl_migration.c	2020-06-06 20:20:32.325834590 +0100
@@ -0,0 +1,9 @@
+#include "libxl_osdeps.h"
+
+#include "libxl_internal.h"
+
+int libxl_save_nvmcs_state(libxl_ctx * ctx, void * state, int step, unsigned int domid)
+{
+    int  rc = xc_save_nvmcs(ctx->xch, state, step, domid);
+    return rc;
+}
diff -ruN /root/xen/xen-original/tools/libxl/Makefile /root/xen/xen-modded/tools/libxl/Makefile
--- /root/xen/xen-original/tools/libxl/Makefile	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/tools/libxl/Makefile	2020-06-06 20:20:32.324834606 +0100
@@ -139,7 +139,7 @@
 			libxl_dom_suspend.o libxl_dom_save.o libxl_usb.o \
 			libxl_vtpm.o libxl_nic.o libxl_disk.o libxl_console.o \
 			libxl_cpupool.o libxl_mem.o libxl_sched.o libxl_tmem.o \
-			libxl_9pfs.o libxl_domain.o libxl_vdispl.o \
+			libxl_9pfs.o libxl_migration.o libxl_faultinjection.o libxl_domain.o libxl_vdispl.o \
                         libxl_pvcalls.o $(LIBXL_OBJS-y)
 LIBXL_OBJS += libxl_genid.o
 LIBXL_OBJS += _libxl_types.o libxl_flask.o _libxl_types_internal.o
@@ -169,7 +169,7 @@
 TEST_PROG_OBJS += $(foreach t, $(LIBXL_TESTS_PROGS),test_$t.o) test_common.o
 TEST_PROGS += $(foreach t, $(LIBXL_TESTS_PROGS),test_$t)
 
-$(LIBXL_OBJS) $(LIBXL_TEST_OBJS): CFLAGS += $(CFLAGS_LIBXL) -include $(XEN_ROOT)/tools/config.h
+$(LIBXL_OBJS) $(LIBXL_TEST_OBJS): CFLAGS += $(CFLAGS_LIBXL)  -include $(XEN_ROOT)/tools/config.h
 
 AUTOINCS= libxlu_cfg_y.h libxlu_cfg_l.h _libxl_list.h _paths.h \
 	libxlu_disk_l.h _libxl_save_msgs_callout.h _libxl_save_msgs_helper.h
@@ -185,7 +185,6 @@
 
 libxl_dom.o: CFLAGS += -I$(XEN_ROOT)/tools  # include libacpi/x86.h
 libxl_x86_acpi.o: CFLAGS += -I$(XEN_ROOT)/tools
-
 SAVE_HELPER_OBJS = libxl_save_helper.o _libxl_save_msgs_helper.o
 $(SAVE_HELPER_OBJS): CFLAGS += $(CFLAGS_libxenctrl) $(CFLAGS_libxenevtchn)
 
diff -ruN /root/xen/xen-original/tools/xcutils/hypercaller2.c /root/xen/xen-modded/tools/xcutils/hypercaller2.c
--- /root/xen/xen-original/tools/xcutils/hypercaller2.c	1970-01-01 01:00:00.000000000 +0100
+++ /root/xen/xen-modded/tools/xcutils/hypercaller2.c	2020-06-06 20:20:32.325834590 +0100
@@ -0,0 +1,36 @@
+#include <stdio.h>
+#include <stdlib.h>
+#include <xenctrl.h>
+#include <xen/sys/privcmd.h>
+#include <fcntl.h>
+#include <sys/ioctl.h>
+#include <linux/types.h>
+
+int main(int argc, char *argv[])
+{
+int fd;
+int id, tid;
+unsigned long ret, addr, base_pfn;
+	if (argc != 5) {
+		printf("Hypercaller2 received incorrect amount of params\n");
+		return -1;
+	}
+	sscanf(argv[1], "%d", &id);
+	sscanf(argv[2], "%lu", &addr);
+	sscanf(argv[3], "%d", &tid);
+	sscanf(argv[4], "%lu", &base_pfn);
+ privcmd_hypercall_t mycall = {
+            __HYPERVISOR_testing,
+            { id, addr, tid, base_pfn, 0}
+    };
+    fd = open("/proc/xen/privcmd", O_RDWR);
+    if (fd < 0) {
+        printf("Couldnt happen privcmd\n");
+        return -1;
+    }
+    ret = ioctl(fd, IOCTL_PRIVCMD_HYPERCALL, &mycall);
+    printf("%lu\n", ret);
+    return 0;
+}
+
+
diff -ruN /root/xen/xen-original/tools/xcutils/Makefile /root/xen/xen-modded/tools/xcutils/Makefile
--- /root/xen/xen-original/tools/xcutils/Makefile	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/tools/xcutils/Makefile	2020-06-06 20:20:32.325834590 +0100
@@ -11,13 +11,14 @@
 XEN_ROOT	= $(CURDIR)/../..
 include $(XEN_ROOT)/tools/Rules.mk
 
-PROGRAMS = readnotes lsevtchn
+PROGRAMS = readnotes lsevtchn hypercaller2
 
-CFLAGS += -Werror
+CFLAGS +=  -Wdeclaration-after-statement
 
 # incorrectly uses libxc internals
 CFLAGS_readnotes.o  := $(CFLAGS_libxenevtchn) $(CFLAGS_libxenctrl) $(CFLAGS_libxenguest) -I$(XEN_ROOT)/tools/libxc $(CFLAGS_libxencall)
 CFLAGS_lsevtchn.o   := $(CFLAGS_libxenevtchn) $(CFLAGS_libxenctrl)
+CFLAGS_hypercaller2.o   := $(CFLAGS_libxenevtchn) $(CFLAGS_libxenctrl)
 
 .PHONY: all
 all: build
@@ -31,6 +32,9 @@
 lsevtchn: lsevtchn.o
 	$(CC) $(LDFLAGS) $^ -o $@ $(LDLIBS_libxenctrl) $(APPEND_LDFLAGS)
 
+hypercaller2: hypercaller2.o
+	$(CC) $(LDFLAGS) $^ -o $@ $(LDLIBS_libxenctrl) $(LDLIBS_libxenguest) $(APPEND_LDFLAGS)
+
 .PHONY: install
 install: build
 	$(INSTALL_DIR) $(DESTDIR)$(LIBEXEC_BIN)
diff -ruN /root/xen/xen-original/tools/xl/Makefile /root/xen/xen-modded/tools/xl/Makefile
--- /root/xen/xen-original/tools/xl/Makefile	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/tools/xl/Makefile	2020-06-06 20:20:32.325834590 +0100
@@ -2,6 +2,9 @@
 # tools/xl/Makefile
 #
 
+XML2_FLAGS=-I/usr/include/libxml2/
+XML2_LIBS=-lxml2 -lz -lm -ldl
+
 XEN_ROOT = $(CURDIR)/../..
 include $(XEN_ROOT)/tools/Rules.mk
 
@@ -13,7 +16,7 @@
 LDFLAGS += $(PTHREAD_LDFLAGS)
 
 CFLAGS_XL += $(CFLAGS_libxenlight)
-CFLAGS_XL += -Wshadow
+CFLAGS_XL += -Wshadow $(XML2_FLAGS) 
 
 XL_OBJS-$(CONFIG_X86) = xl_psr.o
 XL_OBJS = xl.o xl_cmdtable.o xl_sxp.o xl_utils.o $(XL_OBJS-y)
@@ -21,8 +24,8 @@
 XL_OBJS += xl_vtpm.o xl_block.o xl_nic.o xl_usb.o
 XL_OBJS += xl_sched.o xl_pci.o xl_vcpu.o xl_cdrom.o xl_mem.o
 XL_OBJS += xl_info.o xl_console.o xl_misc.o
-XL_OBJS += xl_vmcontrol.o xl_saverestore.o xl_migrate.o
-XL_OBJS += xl_vdispl.o
+XL_OBJS += xl_vmcontrol.o xl_saverestore.o xl_migrate.o xl_migration.o
+XL_OBJS += xl_vdispl.o xl_faultinjection.o
 
 $(XL_OBJS): CFLAGS += $(CFLAGS_libxentoollog)
 $(XL_OBJS): CFLAGS += $(CFLAGS_XL)
@@ -37,7 +40,7 @@
 all: xl
 
 xl: $(XL_OBJS)
-	$(CC) $(LDFLAGS) -o $@ $(XL_OBJS) $(LDLIBS_libxlutil) $(LDLIBS_libxenlight) $(LDLIBS_libxentoollog) -lyajl $(APPEND_LDFLAGS)
+	$(CC) $(LDFLAGS) -o $@ $(XL_OBJS) $(LDLIBS_libxlutil) $(LDLIBS_libxenlight) $(LDLIBS_libxentoollog) -lyajl $(APPEND_LDFLAGS) $(XML2_LIBS)
 
 .PHONY: install
 install: all
diff -ruN /root/xen/xen-original/tools/xl/xl_cmdtable.c /root/xen/xen-modded/tools/xl/xl_cmdtable.c
--- /root/xen/xen-original/tools/xl/xl_cmdtable.c	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/tools/xl/xl_cmdtable.c	2020-06-06 20:20:32.325834590 +0100
@@ -631,6 +631,17 @@
       "Issue a qemu monitor command to the device model of a domain",
       "<Domain> <Command>",
     },
+	{
+	"save-nvmcs", &main_save_nvmcs, 0, 0,
+	"Test",
+	""
+	},
+	{
+	"inject-fault", &main_inject_fault, 0, 0,
+	"Inject fault in guest VM CPU context",
+	""
+	},
+
 };
 
 int cmdtable_len = sizeof(cmd_table)/sizeof(struct cmd_spec);
diff -ruN /root/xen/xen-original/tools/xl/xl_faultinjection.c /root/xen/xen-modded/tools/xl/xl_faultinjection.c
--- /root/xen/xen-original/tools/xl/xl_faultinjection.c	1970-01-01 01:00:00.000000000 +0100
+++ /root/xen/xen-modded/tools/xl/xl_faultinjection.c	2020-06-06 20:20:32.325834590 +0100
@@ -0,0 +1,44 @@
+#include <fcntl.h>
+#include <inttypes.h>
+#include <signal.h>
+#include <stdlib.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <sys/utsname.h>
+#include <time.h>
+#include <unistd.h>
+
+#include <libxl.h>
+#include <libxl_utils.h>
+#include <libxlutil.h>
+
+#include "xl.h"
+#include "xl_utils.h"
+#include "xl_parse.h"
+
+#define __HYPERVISOR_VIRT_START 0xFFFF800000000000
+#define __HYPERVISOR_VIRT_END   0xFFFF880000000000
+
+int main_inject_fault(int argc, char **argv)
+{
+	unsigned long domid, bit, reg, range_start, range_end;
+
+	// By default range_start and range_end limits injections to the hypervisor region
+	range_start = __HYPERVISOR_VIRT_START;
+	range_end = __HYPERVISOR_VIRT_END;
+
+	if (argc != 4)
+	{
+		fprintf(stderr, "Expecting <domid> <bit> <reg> [range_start] [range_end]\n");
+		return -1;
+	}
+
+	sscanf(argv[1], "%lu", &domid);
+	sscanf(argv[2], "%lu", &bit);
+	sscanf(argv[3], "%lu", &reg);
+	if (argc ==  6) {
+		sscanf(argv[4], "%lu", &range_start);
+		sscanf(argv[5], "%lu", &range_end);
+	}
+	return libxl_inject_fault(ctx, domid, bit, reg, range_start, range_end);
+}
diff -ruN /root/xen/xen-original/tools/xl/xl.h /root/xen/xen-modded/tools/xl/xl.h
--- /root/xen/xen-original/tools/xl/xl.h	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/tools/xl/xl.h	2020-06-06 20:20:32.325834590 +0100
@@ -213,7 +213,8 @@
 int main_psr_mba_show(int argc, char **argv);
 #endif
 int main_qemu_monitor_command(int argc, char **argv);
-
+int main_save_nvmcs(int argc, char **argv);
+int main_inject_fault(int argc, char **argv);
 void help(const char *command);
 
 extern const char *common_domname;
diff -ruN /root/xen/xen-original/tools/xl/xl_migration.c /root/xen/xen-modded/tools/xl/xl_migration.c
--- /root/xen/xen-original/tools/xl/xl_migration.c	1970-01-01 01:00:00.000000000 +0100
+++ /root/xen/xen-modded/tools/xl/xl_migration.c	2020-06-06 20:20:32.325834590 +0100
@@ -0,0 +1,191 @@
+#include <fcntl.h>
+#include <inttypes.h>
+#include <signal.h>
+#include <stdlib.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <sys/utsname.h>
+#include <time.h>
+#include <unistd.h>
+
+#include <libxl.h>
+#include <libxl_utils.h>
+#include <libxlutil.h>
+
+#include "xl.h"
+#include "xl_utils.h"
+#include "xl_parse.h"
+
+#include <libxml/parser.h>
+#include <libxml/tree.h>
+
+#define BUF_SIZE 21
+// TODO: Avoid repeated struct
+struct vmcs_save_state_xl {
+                unsigned char ready; 
+                unsigned long eptp, domid;
+                unsigned long sysenter_cs, sysenter_esp, sysenter_eip;
+                unsigned long es_sel, es_limit, es_base, es_arbytes;
+                unsigned long cs_sel, cs_limit, cs_base, cs_arbytes;
+                unsigned long ss_sel, ss_limit, ss_base, ss_arbytes;
+                unsigned long ds_sel, ds_limit, ds_base, ds_arbytes;
+                unsigned long fs_sel, fs_limit, fs_base, fs_arbytes;
+                unsigned long gs_sel, gs_limit, gs_base, gs_arbytes;
+                unsigned long tr_sel, tr_limit, tr_base, tr_arbytes;
+                unsigned long ldtr_sel, ldtr_limit, ldtr_base, ldtr_arbytes;
+                unsigned long idtr_limit, idtr_base;
+                unsigned long  gdtr_limit, gdtr_base;
+        };
+
+int main_save_nvmcs(int argc, char **argv)
+{
+	struct vmcs_save_state_xl s;
+	int step;
+	unsigned int domid;
+	xmlDocPtr doc = NULL;
+	xmlNodePtr root = NULL;
+	xmlChar buf[BUF_SIZE];
+	LIBXML_TEST_VERSION;
+
+	if (argc != 3)
+	{
+		fprintf(stderr, "Expecting two arguments (step, domid)\n");
+		return -1;
+	}
+
+	sscanf(argv[1], "%d", &step);
+	sscanf(argv[2], "%u", &domid);
+	libxl_save_nvmcs_state(ctx, (void *) &s, step, domid);
+
+	if (step == 2) /* Obtain saved state */
+	{
+		doc = xmlNewDoc(BAD_CAST "1.0");
+		root = xmlNewNode(NULL, BAD_CAST "nvmcs");
+		xmlDocSetRootElement(doc, root);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.sysenter_cs);
+		xmlNewChild(root, NULL, BAD_CAST "sysenter_cs", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.sysenter_esp);
+		xmlNewChild(root, NULL, BAD_CAST "sysenter_esp", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.sysenter_eip);
+		xmlNewChild(root, NULL, BAD_CAST "sysenter_eip", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.es_sel);
+		xmlNewChild(root, NULL, BAD_CAST "es_sel", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.cs_sel);
+		xmlNewChild(root, NULL, BAD_CAST "cs_sel", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.ss_sel);
+		xmlNewChild(root, NULL, BAD_CAST "ss_sel", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.ds_sel);
+		xmlNewChild(root, NULL, BAD_CAST "ds_sel", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.fs_sel);
+		xmlNewChild(root, NULL, BAD_CAST "fs_sel", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.gs_sel);
+		xmlNewChild(root, NULL, BAD_CAST "gs_sel", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.tr_sel);
+		xmlNewChild(root, NULL, BAD_CAST "tr_sel", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.ldtr_sel);
+		xmlNewChild(root, NULL, BAD_CAST "ldtr_sel", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.es_limit);
+		xmlNewChild(root, NULL, BAD_CAST "es_limit", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.cs_limit);
+		xmlNewChild(root, NULL, BAD_CAST "cs_limit", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.ss_limit);
+		xmlNewChild(root, NULL, BAD_CAST "ss_limit", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.ds_limit);
+		xmlNewChild(root, NULL, BAD_CAST "ds_limit", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.fs_limit);
+		xmlNewChild(root, NULL, BAD_CAST "fs_limit", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.gs_limit);
+		xmlNewChild(root, NULL, BAD_CAST "gs_limit", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.tr_limit);
+		xmlNewChild(root, NULL, BAD_CAST "tr_limit", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.ldtr_limit);
+		xmlNewChild(root, NULL, BAD_CAST "ldtr_limit", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.idtr_limit);
+		xmlNewChild(root, NULL, BAD_CAST "idtr_limit", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.gdtr_limit);
+		xmlNewChild(root, NULL, BAD_CAST "gdtr_limit", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.es_base);
+		xmlNewChild(root, NULL, BAD_CAST "es_base", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.cs_base);
+		xmlNewChild(root, NULL, BAD_CAST "cs_base", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.ss_base);
+		xmlNewChild(root, NULL, BAD_CAST "ss_base", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.ds_base);
+		xmlNewChild(root, NULL, BAD_CAST "ds_base", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.fs_base);
+		xmlNewChild(root, NULL, BAD_CAST "fs_base", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.gs_base);
+		xmlNewChild(root, NULL, BAD_CAST "gs_base", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.tr_base);
+		xmlNewChild(root, NULL, BAD_CAST "tr_base", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.ldtr_base);
+		xmlNewChild(root, NULL, BAD_CAST "ldtr_base", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.idtr_base);
+		xmlNewChild(root, NULL, BAD_CAST "idtr_base", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.gdtr_base);
+		xmlNewChild(root, NULL, BAD_CAST "gdtr_base", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.es_arbytes);
+		xmlNewChild(root, NULL, BAD_CAST "es_arbytes", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.cs_arbytes);
+		xmlNewChild(root, NULL, BAD_CAST "cs_arbytes", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.ss_arbytes);
+		xmlNewChild(root, NULL, BAD_CAST "ss_arbytes", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.ds_arbytes);
+		xmlNewChild(root, NULL, BAD_CAST "ds_arbytes", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.fs_arbytes);
+		xmlNewChild(root, NULL, BAD_CAST "fs_arbytes", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.gs_arbytes);
+		xmlNewChild(root, NULL, BAD_CAST "gs_arbytes", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.tr_arbytes);
+		xmlNewChild(root, NULL, BAD_CAST "tr_arbytes", buf);
+
+		xmlStrPrintf(buf, BUF_SIZE, "%lu", s.ldtr_arbytes);
+		xmlNewChild(root, NULL, BAD_CAST "ldtr_arbytes", buf);
+
+
+
+		xmlSaveFormatFileEnc("-", doc, "UTF-8", 1);
+		xmlFreeDoc(doc);
+		xmlCleanupParser();
+		xmlMemoryDump();
+	}
+	return 0;	
+}
diff -ruN /root/xen/xen-original/xen/arch/x86/domain.c /root/xen/xen-modded/xen/arch/x86/domain.c
--- /root/xen/xen-original/xen/arch/x86/domain.c	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/xen/arch/x86/domain.c	2020-06-06 20:20:32.325834590 +0100
@@ -1608,6 +1608,22 @@
     return is_pv_domain(d) && !is_idle_domain(d);
 }
 
+#ifdef CONFIG_FAULT_INJECTION
+#define FLIP(X,Y) X ^= 1UL << Y;
+extern struct fault_injection_reqinfo fault_injection_req;
+extern int enable_fault_injection;
+
+#ifdef CONFIG_FAULT_INJECTION_VERBOSE
+static void print_regs(struct cpu_user_regs * regs)
+{
+	printk("[fault_injection] regs rip %lX rbp %lX rsp %lX rax %lX rbx %lX"
+		" rcx %lX rdx %lX r8 %lX r9 %lX r10 %lX r11 %lX r12 %lX r13 %lX r14 %lX r15 %lX\n",
+		regs->rip, regs->rbp, regs->rsp, regs->rax, regs->rbx, regs->rcx, regs->rdx,
+		regs->r8, regs->r9, regs->r10, regs->r11, regs->r12, regs->r13, regs->r14, regs->r15);
+}
+#endif
+#endif
+
 static void __context_switch(void)
 {
     struct cpu_user_regs *stack_regs = guest_cpu_user_regs();
@@ -1639,7 +1655,70 @@
 
     if ( !is_idle_domain(nd) )
     {
-        memcpy(stack_regs, &n->arch.user_regs, CTXT_SWITCH_STACK_BYTES);
+    #ifdef CONFIG_FAULT_INJECTION
+        struct cpu_user_regs * regs = &n->arch.user_regs;
+        if ((enable_fault_injection == 1) && (fault_injection_req.domid == nd->domain_id) 
+	         && ((regs->rip >= fault_injection_req.start_range) && (regs->rip <= fault_injection_req.end_range)))
+        {
+            #ifdef CONFIG_FAULT_INJECTION_VERBOSE
+            print_regs(&n->arch.user_regs);
+            printk("[fault injection] TDSC %lX\n", get_cycles());
+            #endif
+
+            switch (fault_injection_req.reg) {
+                case 0:
+                    FLIP(n->arch.user_regs.rip, fault_injection_req.bit);
+                    break;
+                case 1:
+                    FLIP(n->arch.user_regs.rsp, fault_injection_req.bit);
+                    break;
+                case 2:
+                    FLIP(n->arch.user_regs.rbp, fault_injection_req.bit);
+                    break;
+                case 3:
+                    FLIP(n->arch.user_regs.rax, fault_injection_req.bit);
+                    break;
+                case 4:
+                    FLIP(n->arch.user_regs.rbx, fault_injection_req.bit);
+                    break;
+                case 5:
+                    FLIP(n->arch.user_regs.rcx, fault_injection_req.bit);
+                    break;
+                case 6:
+                    FLIP(n->arch.user_regs.rdx, fault_injection_req.bit);
+                    break;
+                case 7:
+                    FLIP(n->arch.user_regs.r8, fault_injection_req.bit);
+                    break;
+                case 8:
+                    FLIP(n->arch.user_regs.r9, fault_injection_req.bit);
+                    break;
+                case 9:
+                    FLIP(n->arch.user_regs.r10, fault_injection_req.bit);
+                    break;
+                case 10:
+                    FLIP(n->arch.user_regs.r11, fault_injection_req.bit);
+                    break;
+                case 11:
+                    FLIP(n->arch.user_regs.r12, fault_injection_req.bit);
+                    break;
+                case 12:
+                    FLIP(n->arch.user_regs.r13, fault_injection_req.bit);
+                    break;
+                case 13:
+                    FLIP(n->arch.user_regs.r14, fault_injection_req.bit);
+                    break;
+                case 14:
+                    FLIP(n->arch.user_regs.r15, fault_injection_req.bit);
+                    break;
+                default:
+                    BUG();
+		    }
+            enable_fault_injection = 0;
+	    }
+	#endif
+	memcpy(stack_regs, &n->arch.user_regs, CTXT_SWITCH_STACK_BYTES);
+
         if ( cpu_has_xsave )
         {
             u64 xcr0 = n->arch.xcr0 ?: XSTATE_FP_SSE;
diff -ruN /root/xen/xen-original/xen/arch/x86/guest/hypercall_page.S /root/xen/xen-modded/xen/arch/x86/guest/hypercall_page.S
--- /root/xen/xen-original/xen/arch/x86/guest/hypercall_page.S	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/xen/arch/x86/guest/hypercall_page.S	2020-06-06 20:20:32.325834590 +0100
@@ -61,7 +61,9 @@
 DECLARE_HYPERCALL(tmem_op)
 DECLARE_HYPERCALL(xc_reserved_op)
 DECLARE_HYPERCALL(xenpmu_op)
-
+DECLARE_HYPERCALL(testing)
+DECLARE_HYPERCALL(save_nvmcs)
+DECLARE_HYPERCALL(fault_injection)
 DECLARE_HYPERCALL(arch_0)
 DECLARE_HYPERCALL(arch_1)
 DECLARE_HYPERCALL(arch_2)
diff -ruN /root/xen/xen-original/xen/arch/x86/hvm/vmx/vvmx.c /root/xen/xen-modded/xen/arch/x86/hvm/vmx/vvmx.c
--- /root/xen/xen-original/xen/arch/x86/hvm/vmx/vvmx.c	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/xen/arch/x86/hvm/vmx/vvmx.c	2020-06-06 20:20:32.326834574 +0100
@@ -18,7 +18,7 @@
  * this program; If not, see <http://www.gnu.org/licenses/>.
  *
  */
-
+#include <xen/guest_access.h>
 #include <asm/types.h>
 #include <asm/mtrr.h>
 #include <asm/p2m.h>
@@ -27,6 +27,9 @@
 #include <asm/hvm/vmx/vvmx.h>
 #include <asm/hvm/nestedhvm.h>
 
+extern struct nvmcs_global_state nvmcs_global_state;
+extern spinlock_t nvmcs_lock;
+
 static DEFINE_PER_CPU(u64 *, vvmcs_buf);
 
 static void nvmx_purge_vvmcs(struct vcpu *v);
@@ -2319,6 +2322,16 @@
    }
 }
 
+static inline int nvmcs_has_eptp(unsigned long eptp)
+{
+	int i;
+	for (i = 0; i < nvmcs_global_state.free_slot; i++)
+	{
+		if (nvmcs_global_state.save_states[i].eptp == eptp)
+			return i;
+	}
+	return -1;
+}
 /*
  * L2 VMExit handling
  *    return 1: Done or skip the normal layer 0 hypervisor process.
@@ -2333,8 +2346,93 @@
     struct nestedvcpu *nvcpu = &vcpu_nestedhvm(v);
     struct nestedvmx *nvmx = &vcpu_2_nvmx(v);
     u32 ctrl;
+    struct vmcs_save_state * save_state;
+	int slot_id;
 
-    nvcpu->nv_vmexit_pending = 0;
+
+    if (nvmcs_global_state.enabled == 1)  {
+        unsigned long sysenter;
+        __vmread(GUEST_SYSENTER_EIP, &sysenter);
+
+            if (sysenter != 0) {
+                spin_lock(&nvmcs_lock);
+                slot_id = nvmcs_has_eptp(sysenter);
+                if ((slot_id == -1) && (nvmcs_global_state.next_is_domid == 0))
+                {
+	                 // Unknown EPTP but we are not expecting it
+                } else {
+
+                if (slot_id != -1)
+                {
+	                save_state = &nvmcs_global_state.save_states[slot_id];
+                } else {
+	                printk("Adding new entry at slot %d with sysenter %lX\n", nvmcs_global_state.free_slot, sysenter);
+	                save_state = &nvmcs_global_state.save_states[nvmcs_global_state.free_slot];
+	                //save_state->eptp = nvcpu->nv_p2m->ept.eptp;
+	                save_state->eptp = sysenter;
+	                save_state->domid = nvmcs_global_state.next_is_domid;
+	                nvmcs_global_state.next_is_domid = 0;
+	                ++nvmcs_global_state.free_slot;
+                }
+                //enable_vmcs_save_on_vmexit = 0;
+                __vmread(GUEST_SYSENTER_CS, &save_state->sysenter_cs);
+                __vmread(GUEST_SYSENTER_ESP, &save_state->sysenter_esp);
+                save_state->sysenter_eip = sysenter;
+                __vmread(GUEST_ES_SELECTOR, &save_state->es_sel);
+                __vmread(GUEST_ES_LIMIT,    &save_state->es_limit);
+                __vmread(GUEST_ES_BASE,     &save_state->es_base);
+                __vmread(GUEST_ES_AR_BYTES, &save_state->es_arbytes);
+                __vmread(GUEST_CS_SELECTOR, &save_state->cs_sel);
+                __vmread(GUEST_CS_LIMIT,    &save_state->cs_limit);
+                __vmread(GUEST_CS_BASE,     &save_state->cs_base);
+                __vmread(GUEST_CS_AR_BYTES, &save_state->cs_arbytes);
+                __vmread(GUEST_SS_SELECTOR, &save_state->ss_sel);
+                __vmread(GUEST_SS_LIMIT,    &save_state->ss_limit);
+                __vmread(GUEST_SS_BASE,     &save_state->ss_base);
+                __vmread(GUEST_SS_AR_BYTES, &save_state->ss_arbytes);
+                __vmread(GUEST_DS_SELECTOR, &save_state->ds_sel);
+                __vmread(GUEST_DS_LIMIT,    &save_state->ds_limit);
+                __vmread(GUEST_DS_BASE,     &save_state->ds_base);
+                __vmread(GUEST_DS_AR_BYTES, &save_state->ds_arbytes);
+                __vmread(GUEST_FS_SELECTOR, &save_state->fs_sel);
+                __vmread(GUEST_FS_LIMIT,    &save_state->fs_limit);
+                __vmread(GUEST_FS_BASE,     &save_state->fs_base);
+                __vmread(GUEST_FS_AR_BYTES, &save_state->fs_arbytes);
+                __vmread(GUEST_GS_SELECTOR, &save_state->gs_sel);
+                __vmread(GUEST_GS_LIMIT,    &save_state->gs_limit);
+                __vmread(GUEST_GS_BASE,     &save_state->gs_base);
+                __vmread(GUEST_GS_AR_BYTES, &save_state->gs_arbytes);
+                __vmread(GUEST_TR_SELECTOR, &save_state->tr_sel);
+                __vmread(GUEST_TR_LIMIT,    &save_state->tr_limit);
+                __vmread(GUEST_TR_BASE,     &save_state->tr_base);
+                __vmread(GUEST_TR_AR_BYTES, &save_state->tr_arbytes);
+                __vmread(GUEST_GDTR_LIMIT,  &save_state->gdtr_limit);
+                __vmread(GUEST_GDTR_BASE,   &save_state->gdtr_base);
+                __vmread(GUEST_IDTR_LIMIT,  &save_state->idtr_limit);
+                __vmread(GUEST_IDTR_BASE,   &save_state->idtr_base);
+                __vmread(GUEST_LDTR_SELECTOR, &save_state->ldtr_sel);
+                __vmread(GUEST_LDTR_LIMIT,    &save_state->ldtr_limit);
+                __vmread(GUEST_LDTR_BASE,     &save_state->ldtr_base);
+                __vmread(GUEST_LDTR_AR_BYTES, &save_state->ldtr_arbytes);
+
+                // As found in vmx_get_segment_register, Xen has a different representation of arbytes
+                save_state->tr_arbytes = (!(save_state->tr_arbytes & (1u << 16)) << 7) | (save_state->tr_arbytes & 0x7f) | ((save_state->tr_arbytes >> 4) & 0xf00);
+                save_state->ldtr_arbytes = (!(save_state->ldtr_arbytes & (1u << 16)) << 7) | (save_state->ldtr_arbytes & 0x7f) | ((save_state->ldtr_arbytes >> 4) & 0xf00);
+                save_state->fs_arbytes = (!(save_state->fs_arbytes & (1u << 16)) << 7) | (save_state->fs_arbytes & 0x7f) | ((save_state->fs_arbytes >> 4) & 0xf00);
+                save_state->ds_arbytes = (!(save_state->ds_arbytes & (1u << 16)) << 7) | (save_state->ds_arbytes & 0x7f) | ((save_state->ds_arbytes >> 4) & 0xf00);
+                save_state->ss_arbytes = (!(save_state->ss_arbytes & (1u << 16)) << 7) | (save_state->ss_arbytes & 0x7f) | ((save_state->ss_arbytes >> 4) & 0xf00);
+                save_state->cs_arbytes = (!(save_state->cs_arbytes & (1u << 16)) << 7) | (save_state->cs_arbytes & 0x7f) | ((save_state->cs_arbytes >> 4) & 0xf00);
+                save_state->gs_arbytes = (!(save_state->gs_arbytes & (1u << 16)) << 7) | (save_state->gs_arbytes & 0x7f) | ((save_state->gs_arbytes >> 4) & 0xf00);
+                save_state->es_arbytes = (!(save_state->es_arbytes & (1u << 16)) << 7) | (save_state->es_arbytes & 0x7f) | ((save_state->es_arbytes >> 4) & 0xf00);
+
+                save_state->ready = 1;
+                wmb();
+
+            }
+            spin_unlock(&nvmcs_lock);
+        }
+    }
+	nvcpu->nv_vmexit_pending = 0;
     nvmx->intr.intr_info = 0;
     nvmx->intr.error_code = 0;
 
@@ -2474,7 +2572,12 @@
         if ( ctrl & CPU_BASED_HLT_EXITING )
             nvcpu->nv_vmexit_pending = 1;
         break;
+    /* The below case has been backported from the latest Xen version, 4.13.0.
+	It is not needed for supporting intervm migration but it has been added to avoid repetitive warnings
+	produced by recent Linux kernel versions.
+    */
     case EXIT_REASON_RDTSC:
+    case EXIT_REASON_RDTSCP:
         ctrl = __n2_exec_control(v);
         if ( ctrl & CPU_BASED_RDTSC_EXITING )
             nvcpu->nv_vmexit_pending = 1;
@@ -2485,6 +2588,8 @@
              * avoiding changing guest_tsc and messing up timekeeping in L1
              */
             msr_split(regs, hvm_get_guest_tsc(v) + get_vvmcs(v, TSC_OFFSET));
+            /*if ( exit_reason == EXIT_REASON_RDTSCP )
+                regs->rcx = v->arch.msrs->tsc_aux;*/
             update_guest_eip();
 
             return 1;
diff -ruN /root/xen/xen-original/xen/arch/x86/Kconfig /root/xen/xen-modded/xen/arch/x86/Kconfig
--- /root/xen/xen-original/xen/arch/x86/Kconfig	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/xen/arch/x86/Kconfig	2020-06-06 20:20:32.325834590 +0100
@@ -40,7 +40,7 @@
 config PV_LINEAR_PT
        bool "Support for PV linear pagetables"
        depends on PV
-       default y
+       default n
        ---help---
          Linear pagetables (also called "recursive pagetables") refers
          to the practice of a guest operating system having pagetable
@@ -62,7 +62,7 @@
 
 config SHADOW_PAGING
         bool "Shadow Paging"
-        default y
+        default n
         ---help---
 
           Shadow paging is a software alternative to hardware paging support
diff -ruN /root/xen/xen-original/xen/arch/x86/pv/hypercall.c /root/xen/xen-modded/xen/arch/x86/pv/hypercall.c
--- /root/xen/xen-original/xen/arch/x86/pv/hypercall.c	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/xen/arch/x86/pv/hypercall.c	2020-06-06 20:20:32.326834574 +0100
@@ -82,6 +82,9 @@
     COMPAT_CALL(dm_op),
     HYPERCALL(mca),
     HYPERCALL(arch_1),
+    HYPERCALL(testing),
+    HYPERCALL(save_nvmcs),
+    HYPERCALL(fault_injection)
 };
 
 #undef do_arch_1
@@ -127,15 +130,6 @@
 
 #ifndef NDEBUG
         /* Deliberately corrupt parameter regs not used by this hypercall. */
-        switch ( hypercall_args_table[eax].native )
-        {
-        case 0: rdi = 0xdeadbeefdeadf00dUL;
-        case 1: rsi = 0xdeadbeefdeadf00dUL;
-        case 2: rdx = 0xdeadbeefdeadf00dUL;
-        case 3: r10 = 0xdeadbeefdeadf00dUL;
-        case 4: r8 = 0xdeadbeefdeadf00dUL;
-        case 5: r9 = 0xdeadbeefdeadf00dUL;
-        }
 #endif
         if ( unlikely(tb_init_done) )
         {
@@ -147,19 +141,6 @@
         regs->rax = pv_hypercall_table[eax].native(rdi, rsi, rdx, r10, r8, r9);
 
 #ifndef NDEBUG
-        if ( !curr->hcall_preempted )
-        {
-            /* Deliberately corrupt parameter regs used by this hypercall. */
-            switch ( hypercall_args_table[eax].native )
-            {
-            case 6: regs->r9  = 0xdeadbeefdeadf00dUL;
-            case 5: regs->r8  = 0xdeadbeefdeadf00dUL;
-            case 4: regs->r10 = 0xdeadbeefdeadf00dUL;
-            case 3: regs->rdx = 0xdeadbeefdeadf00dUL;
-            case 2: regs->rsi = 0xdeadbeefdeadf00dUL;
-            case 1: regs->rdi = 0xdeadbeefdeadf00dUL;
-            }
-        }
 #endif
     }
     else
diff -ruN /root/xen/xen-original/xen/common/domain.c /root/xen/xen-modded/xen/common/domain.c
--- /root/xen/xen-original/xen/common/domain.c	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/xen/common/domain.c	2020-06-06 20:20:32.326834574 +0100
@@ -42,6 +42,8 @@
 #include <xen/trace.h>
 #include <xen/tmem.h>
 #include <asm/setup.h>
+#include <asm/hvm/vmx/vmx.h>
+#include <asm/hvm/nestedhvm.h>
 
 #ifdef CONFIG_X86
 #include <asm/guest.h>
@@ -59,6 +61,7 @@
 DEFINE_SPINLOCK(domlist_update_lock);
 DEFINE_RCU_READ_LOCK(domlist_read_lock);
 
+
 #define DOMAIN_HASH_SIZE 256
 #define DOMAIN_HASH(_id) ((int)(_id)&(DOMAIN_HASH_SIZE-1))
 static struct domain *domain_hash[DOMAIN_HASH_SIZE];
@@ -75,6 +78,316 @@
 
 vcpu_info_t dummy_vcpu_info;
 
+// Copied from somewhere in Xen
+static inline bool_t is_epte_valid(ept_entry_t *e)
+{
+    /* suppress_ve alone is not considered valid, so mask it off */
+    return ((e->epte & ~(1ul << 63)) != 0 && e->sa_p2mt != p2m_invalid);
+}
+#define is_epte_superpage(ept_entry)    ((ept_entry)->sp)
+#define is_epte_present(ept_entry)      ((ept_entry)->epte & 0x7)
+
+#define atomic_read_ept_entry(__pepte)                              \
+    ( (ept_entry_t) { .epte = read_atomic(&(__pepte)->epte) } )
+
+
+/* Holds the next free pfn (on L1 B) that we can use for the migration */
+static unsigned long free_pfn;
+#ifdef CONFIG_MIGRATION_PERFMON
+
+static unsigned int totalPages, spPages_2Mb, spPages_1Gb, p2mPages;
+static unsigned int pagesAtLevel[4];
+
+#endif
+
+#ifdef CONFIG_MIGRATION_CHECKSUM_PAGES
+
+static unsigned long sum = 0;
+
+static unsigned char checksum_page(void * p) {
+    unsigned char sum = 0;
+    int i = 0;
+    for (i = 0; i < 512; i++) {
+        sum = (sum + ((unsigned long *) p)[i]) % 256;
+    }
+    return sum;
+}
+
+#endif
+
+/* 
+   Returns and increments the next guest pfn (gpfn) that is available on L1 B.
+   We start from a know (assumed) free pfn and increment from there until there is available memory.
+   We depend on L1 B pre-allocating the required pages on the expected location for this purpose.
+*/
+static unsigned long find_next_free_gpfn(struct domain * d, int page_order)
+{
+    struct p2m_domain *p2m = p2m_get_hostp2m(d);
+    unsigned long pfn = free_pfn;
+    BUG_ON(pfn > p2m->max_mapped_pfn);
+    free_pfn += (1 << page_order);
+    return pfn;
+}
+
+/* Replaces the EPT entry mapping to point to new_mfn. Required because we are using a different gpfn in L1 B than was used by L1 A */
+static void replace_ept_mapping(ept_entry_t *epte, unsigned long new_mfn)
+{
+    BUG_ON(epte == NULL);
+    epte->mfn = new_mfn;	
+}
+
+/* Function that performs the gpfn remapping operation between L1's */
+static int update_ept_for_new_host(unsigned int source_domid, unsigned int target_domid, unsigned long source_gpfn, int page_order, int level, ept_entry_t * parent_epte, struct page_info * page, unsigned long mfn)
+{
+    unsigned long target_gpfn;
+    struct domain * sourceD, * targetD;
+    int rc;
+
+    sourceD = rcu_lock_domain_by_id(source_domid);
+    targetD = rcu_lock_domain_by_id(target_domid);
+
+    BUG_ON(sourceD == NULL);
+    BUG_ON(targetD == NULL);
+    BUG_ON(!page);
+
+    target_gpfn = find_next_free_gpfn(targetD, page_order);
+
+    spin_lock(&sourceD->page_alloc_lock);
+    page_list_del(page, &sourceD->page_list);
+    spin_unlock(&sourceD->page_alloc_lock);
+
+    rc = guest_physmap_remove_page(sourceD, _gfn(source_gpfn), _mfn(mfn), page_order);
+
+    rc = guest_physmap_add_entry(targetD, _gfn(target_gpfn), _mfn(mfn), page_order, p2m_ram_rw); // p2m_ram_rw
+    if (rc != 0) 
+    {
+        printk("Failed rc=%d mfn=%lX gfn=%lX\n", rc, target_gpfn, mfn);
+    }
+
+    spin_lock(&targetD->page_alloc_lock);
+    page_list_add_tail(page, &targetD->page_list);
+    page_set_owner(page, targetD);
+    spin_unlock(&targetD->page_alloc_lock);
+
+    rcu_unlock_domain(sourceD);
+    rcu_unlock_domain(targetD);
+
+    return target_gpfn;
+    }
+
+/* Iterates over EPT page table structure of L2 (in L1 A) and migrates every page to L1 B, rewritting the EPT structure as required */
+static int iterate_ept_structures(struct domain * d, unsigned long addr, int level, int page_order, struct domain * t, ept_entry_t * parent_epte)
+{
+    ept_entry_t * mapping;
+    unsigned long mfn;
+    int i;
+    struct page_info * page;
+
+    #ifdef CONFIG_MIGRATION_CHECKSUM_PAGES
+    unsigned char tmp;
+    #endif
+    unsigned long new_gpfn;
+
+    #ifdef CONFIG_MIGRATION_PERFMON
+    ++totalPages;
+    #endif
+
+    // Some checks...
+    //BUG_ON(page_order != PAGE_ORDER_4K);
+    BUG_ON((level < 0) || (level > 4));
+
+    // NOTE: addr is realy a GFN not addr.
+    // Since this is an EPT L12 P2M it uses GPFN from L1 which must be converted to MFN @ L0
+    page = get_page_from_gfn(d, addr, NULL, P2M_ALLOC);
+    BUG_ON(!page);
+
+    mfn = mfn_x(page_to_mfn(page));
+    BUG_ON(!mfn_valid(_mfn(mfn)));
+
+
+    new_gpfn = update_ept_for_new_host(d->domain_id, t->domain_id, addr, page_order, level, parent_epte, page, mfn);
+    BUG_ON(new_gpfn < 0);
+
+    #ifdef CONFIG_MIGRATION_CHECKSUM_PAGES
+    mapping = (ept_entry_t *) map_domain_page(_mfn(mfn));
+    if (!mapping) WARN();
+    tmp = checksum_page((void *)mapping);
+    sum += tmp;
+    if (level != 4) printk("%d:%lX:%lX:%X\n",level, new_gpfn, mfn, tmp);
+    unmap_domain_page((void *)mapping);
+    #endif
+
+
+    // Level 4 is not an EPT (p2m) page but rather a host page
+    // Page orders bigger than 4K means a supepage
+    if ((page_order != PAGE_ORDER_4K) || (level == 4)) 
+    { 
+        return new_gpfn; 
+    }
+
+    #ifdef CONFIG_MIGRATION_PERFMON
+    ++p2mPages;
+    ++pagesAtLevel[level];
+    #endif
+
+    // Levels < 4 are EPT pages that must be iterated
+    mapping = (ept_entry_t *) map_domain_page(_mfn(mfn));
+    for (i = 0; i < 512; i++)
+    {
+        unsigned long new_tmp;
+        ept_entry_t tmp = atomic_read_ept_entry(&mapping[i]);
+        if ((is_epte_valid(&tmp)) && (is_epte_present(&tmp)))  
+        {
+            if (is_epte_superpage(&tmp)) 
+            {
+                int page_order2 = 0;
+
+                BUG_ON((level < 1) || (level > 2));
+                if (level == 1) page_order2 = PAGE_ORDER_1G;
+                else if (level == 2) page_order2 = PAGE_ORDER_2M;
+                new_tmp = iterate_ept_structures(d, (unsigned long) tmp.mfn, level + 1, page_order2, t, &tmp);
+                replace_ept_mapping(&mapping[i], new_tmp);
+                #ifdef CONFIG_MIGRATION_PERFMON
+                if (page_order2 == PAGE_ORDER_2M)
+	                ++spPages_2Mb;
+                else
+	                ++spPages_1Gb;
+                #endif
+            } else {
+                new_tmp = iterate_ept_structures(d, (unsigned long) tmp.mfn, level + 1, PAGE_ORDER_4K, t, &tmp);
+                replace_ept_mapping(&mapping[i], new_tmp);
+            }
+        }
+    }
+
+    unmap_domain_page((void *) mapping);
+    put_page(page);
+    return new_gpfn;
+}
+
+spinlock_t nvmcs_lock;
+struct nvmcs_global_state nvmcs_global_state;
+
+/* Hypercall entry point - Monitoring VMCS prior to migration for obtaining required CPU state */
+unsigned long do_save_nvmcs(XEN_GUEST_HANDLE_PARAM(void) p, unsigned long a, unsigned int domid)
+{
+    int i, slot = -1;
+    int rc = 0;
+    if (a == 1) 
+    {
+        spin_lock(&nvmcs_lock);
+        nvmcs_global_state.next_is_domid = domid;
+        nvmcs_global_state.enabled = 1;
+        slot = nvmcs_global_state.free_slot;
+        memset((void *) &nvmcs_global_state.save_states[slot], 0x0, sizeof(struct vmcs_save_state));
+        wmb();
+        spin_unlock(&nvmcs_lock);
+
+        while (nvmcs_global_state.save_states[slot].ready == 0) { rmb(); }
+
+    } else if (a == 2) {
+        spin_lock(&nvmcs_lock);
+        // Find desired save_state
+        for (i = 0; i < nvmcs_global_state.free_slot; i++)
+        {
+            if (nvmcs_global_state.save_states[i].domid == domid)
+            {
+	            slot = i;
+	            break;
+            }
+        }
+        if (slot == -1) return 2;
+
+        // Busy wait until the data is filled (may lock up the system)
+        rc = copy_to_guest(p, &nvmcs_global_state.save_states[slot], 1);
+
+        spin_unlock(&nvmcs_lock);
+    }
+    return 1;
+}
+
+/* Hypercall entry point - Performing memory page migration between domains */
+unsigned long do_testing(unsigned long domain_id, unsigned long eptp_mfn, unsigned long target_domid, unsigned long base_pfn)
+{
+    struct domain * d = get_domain_by_id(domain_id);
+    struct domain * t = get_domain_by_id(target_domid);
+    ept_entry_t eptp;
+    unsigned long rc = 0;
+
+    free_pfn = base_pfn;
+    eptp.epte  = eptp_mfn;
+
+    if ((d == NULL) || (t == NULL)) {
+        printk("Leaving because couldnt find the domains\n");
+        printk("%ld %ld %lX %p %p\n", domain_id, target_domid, eptp_mfn, d, t);
+        return -1;
+    }
+
+    rmb();
+    wmb();
+    #ifdef CONFIG_MIGRATION_PERFMON
+    totalPages = 0;
+    spPages_2Mb = 0;
+    spPages_1Gb = 0;
+    p2mPages = 0;
+    memset(pagesAtLevel, 0, 4 * sizeof(unsigned int));
+    #endif
+
+    printk("Old EPTP %lx MFN %lX\n", eptp.epte, (unsigned long) eptp.mfn);
+    rc = iterate_ept_structures(d, eptp.mfn, 0, PAGE_ORDER_4K, t, NULL);
+    eptp.mfn = rc;
+
+    #ifdef CONFIG_MIGRATION_PERFMON
+    printk("[stats] Total Pages: %u\n[stats] Superpages (1 Gb): %u\n[stats] Superpages (2 Mb): %u\n[stats] P2M pages: %u\n", totalPages, spPages_1Gb, spPages_2Mb, p2mPages);
+    printk("[stats] Pages @ L0 %u L1 %u L2 %u L3 %u\n", pagesAtLevel[0], pagesAtLevel[1], pagesAtLevel[2], pagesAtLevel[3]);
+    #endif
+
+    printk("New EPTP %lX %ld MFN %lX\n", eptp.epte, eptp.epte,  rc);
+    printk("%lu\n", eptp.epte);
+    #ifdef CONFIG_MIGRATION_CHECKSUM_PAGES
+    printk("sum %lX\n", sum);
+    #endif
+    wmb();
+    flush_tlb_all();
+
+    return rc;
+}
+
+
+#ifdef CONFIG_FAULT_INJECTION
+int enable_fault_injection = 0;
+struct fault_injection_reqinfo fault_injection_req;
+#endif
+
+unsigned long do_fault_injection(unsigned long target_domid, unsigned long  bit, unsigned long reg, unsigned long start_range, unsigned long end_range)
+{
+    #ifdef CONFIG_FAULT_INJECTION
+    struct domain * d = get_domain_by_id(target_domid);
+
+    if (d) {
+        if (bit > 63) {
+            printk("[fault injection] bit %lu out of range\n", bit);
+            return 1;
+        }
+
+        fault_injection_req.domid = target_domid;
+        fault_injection_req.bit = bit;
+        fault_injection_req.reg = reg;
+        fault_injection_req.start_range = start_range;
+        fault_injection_req.end_range = end_range;
+        enable_fault_injection = 1;
+        mb();
+        return 0;
+    } else {
+        printk("[fault injection] unknown domid %ld\n", target_domid);
+        return 3;
+    }
+    #else
+    return 4;
+    #endif
+}
+
+
 static void __domain_finalise_shutdown(struct domain *d)
 {
     struct vcpu *v;
@@ -1623,3 +1936,4 @@
  * indent-tabs-mode: nil
  * End:
  */
+
diff -ruN /root/xen/xen-original/xen/common/Kconfig /root/xen/xen-modded/xen/common/Kconfig
--- /root/xen/xen-original/xen/common/Kconfig	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/xen/common/Kconfig	2020-06-06 20:20:32.326834574 +0100
@@ -57,7 +57,7 @@
 
 config KEXEC
 	bool "kexec support"
-	default y
+	default n
 	depends on HAS_KEXEC
 	---help---
 	  Allows a running Xen hypervisor to be replaced with another OS
@@ -234,7 +234,7 @@
 
 config LIVEPATCH
 	bool "Live patching support"
-	default X86
+	default n
 	depends on HAS_BUILD_ID = "y"
 	---help---
 	  Allows a running Xen hypervisor to be dynamically patched using
diff -ruN /root/xen/xen-original/xen/include/asm-x86/hypercall.h /root/xen/xen-modded/xen/include/asm-x86/hypercall.h
--- /root/xen/xen-original/xen/include/asm-x86/hypercall.h	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/xen/include/asm-x86/hypercall.h	2020-06-06 20:20:32.326834574 +0100
@@ -11,6 +11,7 @@
 #include <public/arch-x86/xen-mca.h> /* for do_mca */
 #include <asm/paging.h>
 
+
 typedef unsigned long hypercall_fn_t(
     unsigned long, unsigned long, unsigned long,
     unsigned long, unsigned long, unsigned long);
@@ -135,6 +136,10 @@
     unsigned int which,
     unsigned long base);
 
+extern unsigned long do_testing(unsigned long domain_id, unsigned long eptp_mfn, unsigned long target_domid, unsigned long base_pfn);
+extern unsigned long do_fault_injection(unsigned long target_domid, unsigned long  bit, unsigned long reg, unsigned long start_range, unsigned long end_range);
+extern unsigned long do_save_nvmcs(XEN_GUEST_HANDLE_PARAM(void) p, unsigned long a, unsigned int domid);
+
 #ifdef CONFIG_COMPAT
 
 #include <compat/arch-x86/xen.h>
diff -ruN /root/xen/xen-original/xen/include/public/domctl.h /root/xen/xen-modded/xen/include/public/domctl.h
--- /root/xen/xen-original/xen/include/public/domctl.h	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/xen/include/public/domctl.h	2020-06-06 20:20:32.326834574 +0100
@@ -121,6 +121,38 @@
 typedef struct xen_domctl_getdomaininfo xen_domctl_getdomaininfo_t;
 DEFINE_XEN_GUEST_HANDLE(xen_domctl_getdomaininfo_t);
 
+	/* Some state that is essenetial for a sucessfull inter-hypervisor migration and which exists in VMCS is not cached by Xen 
+           We must use vmread during a nested L2 vmexit to obtain it, and we use this structure to pass it back to userspace.
+        */
+	struct vmcs_save_state {
+                //XEN_GUEST_HANDLE_PARAM(void) guest_buffer;
+                unsigned char ready; 
+                unsigned long eptp, domid;
+                unsigned long sysenter_cs, sysenter_esp, sysenter_eip;
+                unsigned long es_sel, es_limit, es_base, es_arbytes;
+                unsigned long cs_sel, cs_limit, cs_base, cs_arbytes;
+                unsigned long ss_sel, ss_limit, ss_base, ss_arbytes;
+                unsigned long ds_sel, ds_limit, ds_base, ds_arbytes;
+                unsigned long fs_sel, fs_limit, fs_base, fs_arbytes;
+                unsigned long gs_sel, gs_limit, gs_base, gs_arbytes;
+                unsigned long tr_sel, tr_limit, tr_base, tr_arbytes;
+                unsigned long ldtr_sel, ldtr_limit, ldtr_base, ldtr_arbytes;
+                unsigned long idtr_limit, idtr_base;
+                unsigned long  gdtr_limit, gdtr_base;
+        };
+
+	typedef struct vmcs_save_state vmcs_save_state_t;
+        DEFINE_XEN_GUEST_HANDLE(vmcs_save_state_t);
+
+        #define MAX_NVMCS 32
+        struct nvmcs_global_state {
+                unsigned char enabled;
+                unsigned char free_slot;
+                unsigned int next_is_domid;
+                struct vmcs_save_state save_states[MAX_NVMCS];
+        };
+
+
 
 /* XEN_DOMCTL_getpageframeinfo */
 
diff -ruN /root/xen/xen-original/xen/include/public/xen.h /root/xen/xen-modded/xen/include/public/xen.h
--- /root/xen/xen-original/xen/include/public/xen.h	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/xen/include/public/xen.h	2020-06-06 20:20:32.327834558 +0100
@@ -121,6 +121,9 @@
 #define __HYPERVISOR_xc_reserved_op       39 /* reserved for XenClient */
 #define __HYPERVISOR_xenpmu_op            40
 #define __HYPERVISOR_dm_op                41
+#define __HYPERVISOR_testing              42
+#define __HYPERVISOR_save_nvmcs           43
+#define __HYPERVISOR_fault_injection      44
 
 /* Architecture-specific hypercall definitions. */
 #define __HYPERVISOR_arch_0               48
diff -ruN /root/xen/xen-original/xen/include/xen/domain.h /root/xen/xen-modded/xen/include/xen/domain.h
--- /root/xen/xen-original/xen/include/xen/domain.h	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/xen/include/xen/domain.h	2020-06-06 20:20:32.327834558 +0100
@@ -8,6 +8,16 @@
 #include <asm/domain.h>
 #include <asm/numa.h>
 
+#ifdef CONFIG_FAULT_INJECTION
+/* Holds information about a requested fault injection */
+struct fault_injection_reqinfo {
+        unsigned long domid;
+        unsigned long bit;
+        unsigned long reg;
+        unsigned long start_range, end_range;
+};
+#endif
+
 typedef union {
     struct vcpu_guest_context *nat;
     struct compat_vcpu_guest_context *cmp;
diff -ruN /root/xen/xen-original/xen/Kconfig /root/xen/xen-modded/xen/Kconfig
--- /root/xen/xen-original/xen/Kconfig	2018-11-29 14:04:11.000000000 +0000
+++ /root/xen/xen-modded/xen/Kconfig	2020-06-06 20:20:32.325834590 +0100
@@ -4,6 +4,29 @@
 #
 mainmenu "Xen/$SRCARCH $XEN_FULLVERSION Configuration"
 
+menu "Fault Injection"
+
+config FAULT_INJECTION
+	bool "Enable fault injector"
+	default y
+
+config FAULT_INJECTION_VERBOSE
+	depends on FAULT_INJECTION
+	bool "Produce output messages for logging"
+	default y
+
+endmenu
+
+menu "Live inter-vmm migration"
+config MIGRATION_PERFMON
+	bool "Monitors performance and statistics regarding a migration"
+	default y
+
+config MIGRATION_CHECKSUM_PAGES
+	bool "Performs a checksum of every migrated page. Useful for debugging"
+	default n
+endmenu
+
 config SRCARCH
 	string
 	option env="SRCARCH"
